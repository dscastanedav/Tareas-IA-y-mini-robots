# -*- coding: utf-8 -*-
"""
Maximizaci√≥n de la funci√≥n f(x) = x * sin(10œÄx) + 1
==================================================

Este script implementa diferentes m√©todos para encontrar el m√°ximo global
de la funci√≥n f(x) = x * sin(10œÄx) + 1 en el intervalo [0,1].

La funci√≥n tiene m√∫ltiples m√°ximos locales debido al t√©rmino sinusoidal,
lo que la convierte en un problema interesante de optimizaci√≥n global.

Autor: Estudiante IA
Fecha: Julio 2025
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize_scalar, differential_evolution, brute
import warnings
warnings.filterwarnings('ignore')

def funcion_objetivo(x):
    """
    Funci√≥n a maximizar: f(x) = x * sin(10œÄx) + 1
    
    Args:
        x: Valor de entrada en el intervalo [0,1]
    
    Returns:
        Valor de la funci√≥n f(x)
    """
    return x * np.sin(10 * np.pi * x) + 1

def funcion_negativa(x):
    """
    Funci√≥n negativa para usar con minimizadores
    Maximizar f(x) = Minimizar -f(x)
    
    Args:
        x: Valor de entrada
    
    Returns:
        -f(x)
    """
    return -funcion_objetivo(x)

def derivada_funcion(x):
    """
    Derivada anal√≠tica de f(x) = x * sin(10œÄx) + 1
    f'(x) = sin(10œÄx) + 10œÄx * cos(10œÄx)
    
    Args:
        x: Valor de entrada
    
    Returns:
        Valor de la derivada f'(x)
    """
    return np.sin(10 * np.pi * x) + 10 * np.pi * x * np.cos(10 * np.pi * x)

def analizar_funcion():
    """
    Analiza las caracter√≠sticas de la funci√≥n y genera gr√°fico
    """
    print("üîç AN√ÅLISIS DE LA FUNCI√ìN f(x) = x¬∑sin(10œÄx) + 1")
    print("=" * 60)
    
    # Generar puntos para el gr√°fico
    x = np.linspace(0, 1, 1000)
    y = funcion_objetivo(x)
    dy = derivada_funcion(x)
    
    # Crear gr√°fico
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # Gr√°fico de la funci√≥n
    ax1.plot(x, y, 'b-', linewidth=2, label='f(x) = x¬∑sin(10œÄx) + 1')
    ax1.set_xlabel('x')
    ax1.set_ylabel('f(x)')
    ax1.set_title('Funci√≥n Objetivo a Maximizar')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # Encontrar aproximadamente los m√°ximos locales
    maximos_locales = []
    for i in range(1, len(y)-1):
        if y[i] > y[i-1] and y[i] > y[i+1]:
            maximos_locales.append((x[i], y[i]))
    
    # Marcar m√°ximos locales
    if maximos_locales:
        max_x, max_y = zip(*maximos_locales)
        ax1.plot(max_x, max_y, 'ro', markersize=6, label=f'M√°ximos locales ({len(maximos_locales)})')
        ax1.legend()
    
    # Gr√°fico de la derivada
    ax2.plot(x, dy, 'r-', linewidth=2, label="f'(x)")
    ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5, label='f\'(x) = 0')
    ax2.set_xlabel('x')
    ax2.set_ylabel("f'(x)")
    ax2.set_title('Derivada de la Funci√≥n')
    ax2.grid(True, alpha=0.3)
    ax2.legend()
    
    plt.tight_layout()
    plt.savefig('c:/Users/santi/OneDrive/Documentos/Tareas IA y mini robots/3/3.1/analisis_funcion.png', 
                dpi=300, bbox_inches='tight')
    plt.show()
    
    # Estad√≠sticas b√°sicas
    print(f"üìä Estad√≠sticas de la funci√≥n en [0,1]:")
    print(f"   ‚Ä¢ Valor m√≠nimo: {np.min(y):.6f}")
    print(f"   ‚Ä¢ Valor m√°ximo: {np.max(y):.6f}")
    print(f"   ‚Ä¢ N√∫mero de m√°ximos locales aproximados: {len(maximos_locales)}")
    print(f"   ‚Ä¢ Rango de valores: [{np.min(y):.6f}, {np.max(y):.6f}]")
    
    return maximos_locales

def metodo_fuerza_bruta():
    """
    M√©todo de fuerza bruta: evaluar en una grilla fina
    """
    print("\nüî® M√âTODO 1: FUERZA BRUTA")
    print("-" * 40)
    
    # Crear grilla muy fina
    x_grid = np.linspace(0, 1, 10000)
    y_grid = funcion_objetivo(x_grid)
    
    # Encontrar m√°ximo
    idx_max = np.argmax(y_grid)
    x_max = x_grid[idx_max]
    f_max = y_grid[idx_max]
    
    print(f"   üéØ Resultado:")
    print(f"      x* = {x_max:.8f}")
    print(f"      f(x*) = {f_max:.8f}")
    print(f"      Evaluaciones: {len(x_grid)}")
    
    return x_max, f_max

def metodo_scipy_brute():
    """
    M√©todo scipy.optimize.brute (b√∫squeda en grilla)
    """
    print("\nüî¨ M√âTODO 2: SCIPY BRUTE FORCE")
    print("-" * 40)
    
    # Usar scipy brute force
    resultado = brute(funcion_negativa, ranges=[(0, 1)], Ns=1000, full_output=True)
    
    x_max = resultado[0][0]
    f_max = -resultado[1]  # Negativo porque minimizamos -f(x)
    
    print(f"   üéØ Resultado:")
    print(f"      x* = {x_max:.8f}")
    print(f"      f(x*) = {f_max:.8f}")
    print(f"      Evaluaciones: ~1000")
    
    return x_max, f_max

def metodo_golden_section():
    """
    M√©todo de secci√≥n dorada (para funciones unimodales)
    Nota: No funcionar√° bien aqu√≠ porque la funci√≥n es multimodal
    """
    print("\nü•á M√âTODO 3: SECCI√ìN DORADA")
    print("-" * 40)
    
    try:
        resultado = minimize_scalar(funcion_negativa, bounds=(0, 1), method='golden')
        
        x_max = resultado.x
        f_max = -resultado.fun
        
        print(f"   üéØ Resultado (m√°ximo local):")
        print(f"      x* = {x_max:.8f}")
        print(f"      f(x*) = {f_max:.8f}")
        print(f"      Evaluaciones: {resultado.nfev}")
        print(f"   ‚ö†Ô∏è  Nota: Encuentra un m√°ximo local, no necesariamente global")
        
        return x_max, f_max
    
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return None, None

def metodo_diferencial_evolution():
    """
    Algoritmo evolutivo diferencial (bueno para optimizaci√≥n global)
    """
    print("\nüß¨ M√âTODO 4: EVOLUCI√ìN DIFERENCIAL")
    print("-" * 40)
    
    # Configurar evoluci√≥n diferencial
    bounds = [(0, 1)]
    resultado = differential_evolution(funcion_negativa, bounds, 
                                     seed=42, maxiter=100, popsize=15)
    
    x_max = resultado.x[0]
    f_max = -resultado.fun
    
    print(f"   üéØ Resultado:")
    print(f"      x* = {x_max:.8f}")
    print(f"      f(x*) = {f_max:.8f}")
    print(f"      Evaluaciones: {resultado.nfev}")
    print(f"      √âxito: {'‚úÖ' if resultado.success else '‚ùå'}")
    
    return x_max, f_max

def metodo_busqueda_aleatoria():
    """
    B√∫squeda aleatoria Monte Carlo
    """
    print("\nüé≤ M√âTODO 5: B√öSQUEDA ALEATORIA (MONTE CARLO)")
    print("-" * 40)
    
    # Generar puntos aleatorios
    np.random.seed(42)
    n_puntos = 50000
    x_random = np.random.uniform(0, 1, n_puntos)
    y_random = funcion_objetivo(x_random)
    
    # Encontrar el mejor
    idx_max = np.argmax(y_random)
    x_max = x_random[idx_max]
    f_max = y_random[idx_max]
    
    print(f"   üéØ Resultado:")
    print(f"      x* = {x_max:.8f}")
    print(f"      f(x*) = {f_max:.8f}")
    print(f"      Evaluaciones: {n_puntos}")
    
    return x_max, f_max

def metodo_analisis_derivada():
    """
    M√©todo basado en an√°lisis de la derivada
    """
    print("\nüìê M√âTODO 6: AN√ÅLISIS DE DERIVADA")
    print("-" * 40)
    
    # Encontrar ra√≠ces de la derivada (puntos cr√≠ticos)
    x_test = np.linspace(0, 1, 10000)
    dy_test = derivada_funcion(x_test)
    
    # Encontrar cambios de signo (aproximaci√≥n de ra√≠ces)
    puntos_criticos = []
    for i in range(1, len(dy_test)):
        if dy_test[i-1] * dy_test[i] < 0:  # Cambio de signo
            x_critico = x_test[i]
            puntos_criticos.append(x_critico)
    
    # Incluir extremos del intervalo
    puntos_criticos.extend([0, 1])
    
    # Evaluar funci√≥n en todos los puntos cr√≠ticos
    valores = [(x, funcion_objetivo(x)) for x in puntos_criticos]
    
    # Encontrar el m√°ximo
    x_max, f_max = max(valores, key=lambda item: item[1])
    
    print(f"   üéØ Resultado:")
    print(f"      x* = {x_max:.8f}")
    print(f"      f(x*) = {f_max:.8f}")
    print(f"      Puntos cr√≠ticos encontrados: {len(puntos_criticos)}")
    
    return x_max, f_max

def comparar_metodos():
    """
    Compara todos los m√©todos y encuentra el mejor resultado
    """
    print("\nüìä COMPARACI√ìN DE M√âTODOS")
    print("=" * 60)
    
    metodos = [
        ("Fuerza Bruta", metodo_fuerza_bruta),
        ("SciPy Brute", metodo_scipy_brute),
        ("Secci√≥n Dorada", metodo_golden_section),
        ("Evoluci√≥n Diferencial", metodo_diferencial_evolution),
        ("B√∫squeda Aleatoria", metodo_busqueda_aleatoria),
        ("An√°lisis Derivada", metodo_analisis_derivada)
    ]
    
    resultados = []
    
    for nombre, metodo in metodos:
        try:
            x_opt, f_opt = metodo()
            if x_opt is not None and f_opt is not None:
                resultados.append((nombre, x_opt, f_opt))
        except Exception as e:
            print(f"   ‚ùå Error en {nombre}: {e}")
    
    # Mostrar comparaci√≥n
    print(f"\nüìà RESUMEN DE RESULTADOS:")
    print(f"{'M√©todo':<20} {'x*':<12} {'f(x*)':<12}")
    print("-" * 50)
    
    for nombre, x, f in resultados:
        print(f"{nombre:<20} {x:<12.8f} {f:<12.8f}")
    
    # Encontrar el mejor resultado
    if resultados:
        mejor = max(resultados, key=lambda item: item[2])
        print(f"\nüèÜ MEJOR RESULTADO:")
        print(f"   M√©todo: {mejor[0]}")
        print(f"   x* = {mejor[1]:.8f}")
        print(f"   f(x*) = {mejor[2]:.8f}")
        
        # Verificar que est√° en el dominio
        if 0 <= mejor[1] <= 1:
            print(f"   ‚úÖ Soluci√≥n v√°lida en el dominio [0,1]")
        else:
            print(f"   ‚ö†Ô∏è  Soluci√≥n fuera del dominio")
        
        return mejor
    
    return None

def visualizar_resultado_final(mejor_resultado):
    """
    Crea una visualizaci√≥n final con el mejor resultado
    """
    if mejor_resultado is None:
        return
    
    nombre, x_opt, f_opt = mejor_resultado
    
    # Generar puntos para el gr√°fico
    x = np.linspace(0, 1, 1000)
    y = funcion_objetivo(x)
    
    # Crear gr√°fico final
    plt.figure(figsize=(12, 8))
    
    # Gr√°fico principal
    plt.subplot(2, 1, 1)
    plt.plot(x, y, 'b-', linewidth=2, label='f(x) = x¬∑sin(10œÄx) + 1')
    plt.plot(x_opt, f_opt, 'ro', markersize=10, label=f'M√°ximo global\n({x_opt:.6f}, {f_opt:.6f})')
    plt.xlabel('x')
    plt.ylabel('f(x)')
    plt.title(f'Maximizaci√≥n de f(x) = x¬∑sin(10œÄx) + 1\nM√©todo ganador: {nombre}')
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    # Zoom alrededor del m√°ximo
    plt.subplot(2, 1, 2)
    delta = 0.05
    x_zoom = np.linspace(max(0, x_opt-delta), min(1, x_opt+delta), 200)
    y_zoom = funcion_objetivo(x_zoom)
    plt.plot(x_zoom, y_zoom, 'b-', linewidth=2)
    plt.plot(x_opt, f_opt, 'ro', markersize=10)
    plt.xlabel('x')
    plt.ylabel('f(x)')
    plt.title(f'Zoom alrededor del m√°ximo (¬±{delta})')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('c:/Users/santi/OneDrive/Documentos/Tareas IA y mini robots/3/3.1/resultado_final.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """
    Funci√≥n principal que ejecuta todos los m√©todos
    """
    print("üéØ MAXIMIZACI√ìN DE f(x) = x¬∑sin(10œÄx) + 1 EN [0,1]")
    print("=" * 60)
    
    # 1. Analizar la funci√≥n
    maximos_locales = analizar_funcion()
    
    # 2. Aplicar diferentes m√©todos
    mejor_resultado = comparar_metodos()
    
    # 3. Visualizar resultado final
    visualizar_resultado_final(mejor_resultado)
    
    # 4. An√°lisis final
    print(f"\nüî¨ AN√ÅLISIS FINAL:")
    print(f"   ‚Ä¢ La funci√≥n tiene m√∫ltiples m√°ximos locales debido al t√©rmino sin(10œÄx)")
    print(f"   ‚Ä¢ El factor x hace que los m√°ximos cerca de x=1 sean m√°s altos")
    print(f"   ‚Ä¢ Los m√©todos globales (evoluci√≥n diferencial, fuerza bruta) son m√°s confiables")
    print(f"   ‚Ä¢ El m√°ximo global te√≥rico est√° cerca de x ‚âà 0.95-0.98")

if __name__ == "__main__":
    main()
